{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stall prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Prediction of the pressure profil of an aircraft wing based on deep learning.\n",
    " Our goal is to use pressure predictions to prevent aircraft stalls.\n",
    " The advantage of deep learning in this case is that it requires very little computation compared with real-time simulations, and delivers rapid results that can be used by pilots or drones in their piloting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using data coming from the deepstall project : https://projects.asl.ethz.ch/datasets/doku.php?id=deepstall\n",
    "\n",
    "The data we have is in h5df, to visualize it, we can use : https://myhdf5.hdfgroup.org/\n",
    "\n",
    "Important question : Continuous regression or classification ?\n",
    "\n",
    "Goal : predict pressure field (dp1, dp2, dp3, dp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data Importation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2 dataset : one in wind tunnel and another in real flight condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548\n",
      "506\n",
      "['07_54_01.ulg', '08_12_24.ulg', '08_29_12.ulg', '08_39_56.ulg', '08_47_27.ulg', '08_50_41.ulg', '09_14_44.ulg', '09_14_52.ulg', '09_40_38.ulg', '09_58_51.ulg', '10_19_49.ulg', '10_53_14.ulg', '11_12_32.ulg', '13_00_54.ulg', '13_14_24.ulg', '13_53_32.ulg', '14_10_28.ulg', '14_29_32.ulg']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Data Managing\n",
    "import seaborn as sns # visual tool\n",
    "import matplotlib.pyplot as plt # visual tool\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "\n",
    "import h5py # to deal with h5p file\n",
    "\n",
    "\n",
    "\n",
    "file_FD = h5py.File('Flight_Data/FD_cal.h5', \"r\")\n",
    "file_WT = h5py.File('Wind_Tunnel/WT_cal.h5', \"r\")\n",
    "\n",
    "FD_keys = list(file_FD.keys())\n",
    "WT_keys = list(file_WT.keys())\n",
    "\n",
    "FD_attribute =list(file_FD[FD_keys[0]].keys())\n",
    "print(len(FD_attribute)) #548\n",
    "\n",
    "WT_attribute =list(file_WT[WT_keys[0]].keys())\n",
    "print(len(WT_attribute)) #506 \n",
    "\n",
    "data_WT = {}\n",
    "data_FD = {}\n",
    "list_keys_WT = list(file_WT.keys())\n",
    "list_keys_FD = list(file_FD.keys())\n",
    "print(list_keys_FD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "common_attr = ['airflow_aoa_0.aoa_rad', 'airflow_slip_0.slip_rad', 'airspeed_0.true_airspeed_m_s', 'airspeed_1.true_airspeed_m_s',\n",
    "     'sdp31module_0.dP1_4', 'sdp31module_0.dP1_3', 'sdp31module_0.dP1_2','sdp31module_0.dP1_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned data column number : 8 uncleaned :548\n"
     ]
    }
   ],
   "source": [
    "print(\"cleaned data column number : \" + str(len(common_attr)) + \" uncleaned :\"  + str(len(FD_attribute)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From h5d to dict and to pandas dataframe format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for each key of each h5d file we create a dict which will be later transform into a pandas dataframe\n",
    "dicts_list_WT = [{} for _ in range(len(list_keys_WT))]\n",
    "dicts_list_FD = [{} for _ in range(len(list_keys_FD))]\n",
    "\n",
    "# Populate the list of dict\n",
    "for _ in range(len(list_keys_WT)):\n",
    "    for attr in common_attr:\n",
    "        dicts_list_WT[_][attr] = file_WT[list_keys_WT[_]][attr][0]\n",
    "for _ in range(len(list_keys_FD)):\n",
    "    for attr in common_attr:\n",
    "        dicts_list_FD[_][attr] = file_FD[list_keys_FD[_]][attr][0]\n",
    "    \n",
    "global_dict_list = dicts_list_FD + dicts_list_WT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From dicts to pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "an important decision is to be made here: are we going to mix all our data in one massive dataframe ? Or are we going to make small ones ?\n",
    "\n",
    "For each keys (for exemple '11_aoa_sweep_m5') of the dataframe there is an environmental context, for exemple the experiment as realized in a wind tunnel or outside, during a foggy day or not, using this attack angle or this one. All those informations have an impact on the data, so if we mix datas we also mix contexts and we lose the **contextual information**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15727, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_list_WT = [pd.DataFrame() for _ in range(3)]\n",
    "for _ in range(len(df_list_WT)):\n",
    "    df_list_WT[_] = pd.DataFrame.from_dict(dicts_list_WT[_])\n",
    "    #rm_constant_field(df_list[_]) might not be not a good idea\n",
    "\n",
    "#df_list_FD = [pd.DataFrame() for _ in range(len(dicts_list_FD))]\n",
    "#for _ in range(len(df_list)):\n",
    "    #df_list[_] = pd.DataFrame.from_dict(dicts_list_FD[_])\n",
    "    #rm_constant_field(df_list[_]) might not be not a good idea    \n",
    "\n",
    "\n",
    "DF = pd.concat(df_list_WT)\n",
    "print(DF.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "1) Reduce the dataset to core information\n",
    "2) Prepare the data for the MLP:  data preparaion: data normalization, \n",
    "3) Create MLP and set hyperparameter: Net class creation : Layers, numb of layers, activaion func, (with torch)\n",
    "4) Define training set, epochs, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airflow_aoa_0.aoa_rad</th>\n",
       "      <th>airflow_slip_0.slip_rad</th>\n",
       "      <th>airspeed_0.true_airspeed_m_s</th>\n",
       "      <th>airspeed_1.true_airspeed_m_s</th>\n",
       "      <th>sdp31module_0.dP1_4</th>\n",
       "      <th>sdp31module_0.dP1_3</th>\n",
       "      <th>sdp31module_0.dP1_2</th>\n",
       "      <th>sdp31module_0.dP1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.557741</td>\n",
       "      <td>-0.786432</td>\n",
       "      <td>-0.676724</td>\n",
       "      <td>-0.232048</td>\n",
       "      <td>0.287452</td>\n",
       "      <td>0.529745</td>\n",
       "      <td>0.325550</td>\n",
       "      <td>0.725582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.553250</td>\n",
       "      <td>-0.678135</td>\n",
       "      <td>-0.665277</td>\n",
       "      <td>-0.228996</td>\n",
       "      <td>0.284494</td>\n",
       "      <td>0.525687</td>\n",
       "      <td>0.329221</td>\n",
       "      <td>0.725168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.543928</td>\n",
       "      <td>-0.602315</td>\n",
       "      <td>-0.653831</td>\n",
       "      <td>-0.225943</td>\n",
       "      <td>0.284494</td>\n",
       "      <td>0.527774</td>\n",
       "      <td>0.357780</td>\n",
       "      <td>0.747474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.533110</td>\n",
       "      <td>-0.610619</td>\n",
       "      <td>-0.648216</td>\n",
       "      <td>-0.223654</td>\n",
       "      <td>0.289548</td>\n",
       "      <td>0.530903</td>\n",
       "      <td>0.345967</td>\n",
       "      <td>0.746003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.522301</td>\n",
       "      <td>-0.618923</td>\n",
       "      <td>-0.647792</td>\n",
       "      <td>-0.222054</td>\n",
       "      <td>0.290042</td>\n",
       "      <td>0.528041</td>\n",
       "      <td>0.323777</td>\n",
       "      <td>0.737320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airflow_aoa_0.aoa_rad  airflow_slip_0.slip_rad  \\\n",
       "0              -0.557741                -0.786432   \n",
       "1              -0.553250                -0.678135   \n",
       "2              -0.543928                -0.602315   \n",
       "3              -0.533110                -0.610619   \n",
       "4              -0.522301                -0.618923   \n",
       "\n",
       "   airspeed_0.true_airspeed_m_s  airspeed_1.true_airspeed_m_s  \\\n",
       "0                     -0.676724                     -0.232048   \n",
       "1                     -0.665277                     -0.228996   \n",
       "2                     -0.653831                     -0.225943   \n",
       "3                     -0.648216                     -0.223654   \n",
       "4                     -0.647792                     -0.222054   \n",
       "\n",
       "   sdp31module_0.dP1_4  sdp31module_0.dP1_3  sdp31module_0.dP1_2  \\\n",
       "0             0.287452             0.529745             0.325550   \n",
       "1             0.284494             0.525687             0.329221   \n",
       "2             0.284494             0.527774             0.357780   \n",
       "3             0.289548             0.530903             0.345967   \n",
       "4             0.290042             0.528041             0.323777   \n",
       "\n",
       "   sdp31module_0.dP1_1  \n",
       "0             0.725582  \n",
       "1             0.725168  \n",
       "2             0.747474  \n",
       "3             0.746003  \n",
       "4             0.737320  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "DF_numpy = DF.to_numpy()\n",
    "DF_scaled = scaler.fit_transform(DF_numpy)\n",
    "DF_scaled = pd.DataFrame(DF_scaled, columns = common_attr)\n",
    "DF_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15727, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airflow_aoa_0.aoa_rad</th>\n",
       "      <th>airflow_slip_0.slip_rad</th>\n",
       "      <th>airspeed_0.true_airspeed_m_s</th>\n",
       "      <th>airspeed_1.true_airspeed_m_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8338</th>\n",
       "      <td>-0.001504</td>\n",
       "      <td>-0.004384</td>\n",
       "      <td>10.561196</td>\n",
       "      <td>9.693210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>-0.013948</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>10.508673</td>\n",
       "      <td>9.659739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7843</th>\n",
       "      <td>-0.001934</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>10.546426</td>\n",
       "      <td>9.683150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>0.159616</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>11.154937</td>\n",
       "      <td>10.898161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.166515</td>\n",
       "      <td>0.035636</td>\n",
       "      <td>11.149666</td>\n",
       "      <td>10.838683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airflow_aoa_0.aoa_rad  airflow_slip_0.slip_rad  \\\n",
       "8338              -0.001504                -0.004384   \n",
       "7160              -0.013948                 0.001444   \n",
       "7843              -0.001934                -0.000443   \n",
       "2600               0.159616                -0.010455   \n",
       "747                0.166515                 0.035636   \n",
       "\n",
       "      airspeed_0.true_airspeed_m_s  airspeed_1.true_airspeed_m_s  \n",
       "8338                     10.561196                      9.693210  \n",
       "7160                     10.508673                      9.659739  \n",
       "7843                     10.546426                      9.683150  \n",
       "2600                     11.154937                     10.898161  \n",
       "747                      11.149666                     10.838683  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(DF_scaled.shape)\n",
    "\n",
    "\n",
    "X = DF.drop(['sdp31module_0.dP1_4', 'sdp31module_0.dP1_3', 'sdp31module_0.dP1_2','sdp31module_0.dP1_1'], axis = 1)\n",
    "Y = DF.drop(['airflow_aoa_0.aoa_rad', 'airflow_slip_0.slip_rad', 'airspeed_0.true_airspeed_m_s', 'airspeed_1.true_airspeed_m_s'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexe\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(alpha=0.001, hidden_layer_sizes=(4, 10, 40, 10, 4),\n",
       "             random_state=20)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = MLPRegressor(\n",
    "    activation='relu',\n",
    "    hidden_layer_sizes=(4, 10, 40, 10, 4),\n",
    "    alpha=0.001,\n",
    "    random_state=20,\n",
    "    early_stopping=False)\n",
    "\n",
    "nn.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score : 0.387344290806361\n"
     ]
    }
   ],
   "source": [
    "pred = nn.predict(X_test)\n",
    "\n",
    "print('score :', nn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters of our model are common to all MLP models: \n",
    " - Learning rate\n",
    " - numbers of layers\n",
    " - number of node per layer\n",
    " - (random state fixed to 20)\n",
    "\n",
    "We will search for optimal with Randomized Parameter Optimization (RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[21, 15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "input_size = 4\n",
    "output_size = 4\n",
    "\n",
    "max_hidden_layer = 5\n",
    "min_hidden_layer = 1\n",
    "\n",
    "nb_layer = int(np.floor(random.uniform(min_hidden_layer, max_hidden_layer + 1)))\n",
    "print(nb_layer)\n",
    "\n",
    "max_node_number = 30\n",
    "min_node_number = 10\n",
    "\n",
    "\n",
    "hidden_layer_sizes = [ int(random.uniform(min_node_number, max_node_number + 1)) for _ in range(nb_layer)]\n",
    "print(hidden_layer_sizes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24, 19, 15], [19, 16, 12], [21, 28, 27, 20], [10, 27], [14, 23], [27, 16], [15, 26, 19], [18, 21, 18, 15], [18], [26, 13, 14, 25], [21, 29, 29, 28], [10, 20, 19, 18], [23, 21, 26, 15], [19, 19, 15, 13], [26, 26, 15], [23, 25], [29, 12, 11], [10, 19, 14], [13, 25], [14], [22, 18, 25, 16], [13, 11], [13, 13, 22, 25], [27, 17], [24, 13], [13, 12], [10, 10, 27, 10], [11, 17, 11, 19], [13, 22], [16, 27], [30, 25, 14, 27], [29, 16], [19, 13], [29], [22, 11, 30], [10], [27], [30, 17, 25, 19], [24, 18], [22, 17, 11, 24], [24, 23, 14], [27, 26, 26], [27, 27, 16, 25], [11, 26, 17, 27], [22], [17, 11, 30], [14], [11, 14], [16], [10, 24], [22, 30], [24, 26, 20], [19], [23, 26], [11, 10, 24], [13], [16], [12, 30, 30, 22], [12, 28], [24, 17]]\n",
      "60\n",
      "[1, 2, 0, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 2, 1, 0, 2, 2, 1, 1, 1, 2, 2, 0, 1, 2, 3, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0]\n",
      "[[10, 10, 27, 10], [26, 13, 14, 25], [19, 19, 15, 13], [29, 12, 11], [10, 19, 14], [13, 11], [13, 13, 22, 25], [13, 12], [19, 16, 12], [11, 17, 11, 19], [11, 14], [11, 10, 24], [14, 23], [27, 16], [13, 25], [14], [22, 18, 25, 16], [15, 26, 19], [18, 21, 18, 15], [24, 13], [24, 19, 15], [10, 20, 19, 18], [23, 21, 26, 15], [13, 22], [16, 27], [30, 25, 14, 27], [29, 16], [19, 13], [22, 11, 30], [10], [22, 17, 11, 24], [24, 23, 14], [27, 27, 16, 25], [11, 26, 17, 27], [17, 11, 30], [14], [10, 27], [16], [10, 24], [26, 26, 15], [13], [16], [12, 30, 30, 22], [12, 28], [22], [27, 17], [23, 25], [27], [30, 17, 25, 19], [24, 18], [22, 30], [24, 26, 20], [19], [23, 26], [21, 28, 27, 20], [21, 29, 29, 28], [27, 26, 26], [18], [29], [24, 17]]\n",
      "[[10, 10, 14, 25], [26, 13, 15, 13], [19, 12, 11], [29, 19, 14], [10, 11], [13, 13, 22, 25], [13, 12], [13, 16, 12], [19, 17, 11, 19], [11, 14], [11, 10, 24], [11, 23], [14, 16], [27, 25], [14], [22, 18, 25, 16], [22, 26, 19], [15, 21, 18, 15], [18, 13], [24, 19, 15]]\n",
      "20\n",
      "[3, 3, 2, 1, 2, 2, 2, 3, 1, 2, 2, 1, 2, 0, 1, 1, 0, 2, 1, 1]\n",
      "[[10, 10, 15, 13], [26, 16, 12], [13, 11], [10, 13, 22, 25], [13, 12], [13, 12, 11]]\n",
      "6\n",
      "[4, 2, 2, 2, 2, 3]\n",
      "[[10, 12, 11], [13, 11]]\n",
      "2\n",
      "[3, 2]\n",
      "[[10, 12, 11], [13, 11]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "def ar_double_array(list1, list2):\n",
    "    pass_ = False\n",
    "    index_  = 0\n",
    "    q = 0\n",
    "    j = 0\n",
    "    for i in range(len(list1)):\n",
    "        index_ = i\n",
    "        j = index_\n",
    "        while j <= len(list1) - 1:\n",
    "            if(list1[index_] < list1[j]):\n",
    "                    max_ = list1[j]\n",
    "                    q = list1[index_]\n",
    "                    list1[index_] = list1[j]\n",
    "                    list1[j] = q\n",
    "                    q = list2[index_]\n",
    "                    list2[index_] = list2[j]\n",
    "                    list2[j] = q\n",
    "                    j = index_\n",
    "            j += 1\n",
    "    #print(list1)\n",
    "            \n",
    "    return list2\n",
    "\n",
    "\n",
    "\n",
    "#print(ar_double_array([1, 2, 3, 4, 5], [21, 32, 76, 11, 101]))\n",
    "\n",
    "learning_rate = 0.005\n",
    "random_state = 20\n",
    "\n",
    "def gen_pop(population_size, max_hidden_layer, min_hidden_layer, max_node_number, min_node_number, input_size, output_size):\n",
    "    hidden_layer_sizes = []\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        nb_layer = int(np.floor(random.uniform(min_hidden_layer, max_hidden_layer + 1)))\n",
    "        hidden_layer_sizes = [ int(random.uniform(min_node_number, max_node_number + 1)) for _ in range(nb_layer)]\n",
    "        hidden_layer_sizes.append(output_size)\n",
    "        hidden_layer_sizes.insert(0, input_size)\n",
    "        if hidden_layer_sizes not in population:\n",
    "            population.append(hidden_layer_sizes)\n",
    "    return population\n",
    "\n",
    "def fitness_func(genotype, X_train, y_train,  X_test, y_test):\n",
    "    nn = MLPRegressor(\n",
    "    activation='relu',\n",
    "    hidden_layer_sizes=genotype,\n",
    "    alpha=learning_rate,\n",
    "    random_state=20,\n",
    "    early_stopping=False)\n",
    "\n",
    "    nn.fit(X_train,y_train)\n",
    "\n",
    "    return nn.score(X_test, y_test)\n",
    "\n",
    "def fitness_func_test(genotype):\n",
    "    som = 0\n",
    "    for element in genotype:\n",
    "        if(element < 17):\n",
    "            som+=1\n",
    "    return som\n",
    "          \n",
    "\n",
    "def fitness_func_class(population):\n",
    "    scores = []\n",
    "    print(len(population))\n",
    "    for _ in range(len(population)):\n",
    "        scores.insert(_, fitness_func_test(population[_]))\n",
    "    print(scores)\n",
    "    return ar_double_array(scores, population)\n",
    "    \n",
    "\n",
    "def xover_population(population):\n",
    "    nb_kids = int(len(population) / 3)\n",
    "    index = 0\n",
    "    new_pop = []\n",
    "    kid = []\n",
    "\n",
    "    for _ in range(nb_kids):\n",
    "        cut = int(min(len(population[index]), len(population[index + 1]))/2)\n",
    "        kid += population[index][:cut]\n",
    "        kid += population[index + 1][cut:]\n",
    "        index += 1\n",
    "        new_pop.append(kid)\n",
    "        kid = []\n",
    "    return new_pop\n",
    "\n",
    "def mutation(population, odd1, odd2):\n",
    "    for _ in range(len(population)):\n",
    "        if random.uniform(1, 100) < odd1:\n",
    "            for i in range(len(population[_])):\n",
    "                if random.uniform(1, 100) < odd2:\n",
    "                    if random.uniform(1, 100) < 50:\n",
    "                        population[_][i] += 6\n",
    "                    else:\n",
    "                        population[_][i] -= 6\n",
    "    return population\n",
    "def gen_alg_data(population_size,max_hidden_layer, min_hidden_layer, max_node_number, min_node_number, input_size, output_size,\n",
    "                 X_train, y_train, X_test, y_test):\n",
    "    population = gen_pop(population_size, max_hidden_layer, min_hidden_layer, max_node_number, min_node_number, input_size, output_size)\n",
    "\n",
    "    while(len(population) > 2):\n",
    "        population = fitness_func_class(population)\n",
    "        population = xover_population(population)\n",
    "        population = mutation(population)\n",
    "        \n",
    "    return population\n",
    "\n",
    "pop = [ [ int(random.uniform(min_node_number, max_node_number + 1)) for _ in range(int(random.uniform(min_hidden_layer, max_hidden_layer)))] for _ in range(60)]\n",
    "print(pop)\n",
    "\n",
    "pop = fitness_func_class(pop)\n",
    "print(pop)\n",
    "\n",
    "pop = xover_population(pop)\n",
    "print(pop)\n",
    "\n",
    "pop = fitness_func_class(pop)\n",
    "\n",
    "pop = xover_population(pop)\n",
    "print(pop)\n",
    "\n",
    "pop = fitness_func_class(pop)\n",
    "\n",
    "pop = xover_population(pop)\n",
    "print(pop)\n",
    "\n",
    "pop = fitness_func_class(pop)\n",
    "print(pop)\n",
    "\n",
    "pop = xover_population(pop)\n",
    "print(pop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we transform each dict into a pandas dataframe and check if there is not any constant field\n",
    "def rm_constant_field(df):\n",
    "    \"\"\"\n",
    "    Drops constant value columns of pandas dataframe.\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    for column in df.columns:\n",
    "        if len(df[column].unique()) == 1:\n",
    "            result = result.drop(column,axis=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def id_common_constant(df_list):\n",
    "    list_set_each = [set() for _ in range(len(df_list))]\n",
    "    for _ in range(len(df_list)):\n",
    "        for column in df_list[_].columns:\n",
    "            if(df_list[_][column].unique()) == 1:\n",
    "                list_set_each[_].add(column)\n",
    "    common_set = set.intersection(*list_set_each)\n",
    "    return common_set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
